{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13682547,"sourceType":"datasetVersion","datasetId":8687754}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":3792.580344,"end_time":"2024-10-15T08:05:16.175457","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-15T07:02:03.595113","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2025-11-09T19:43:16.418405Z","iopub.execute_input":"2025-11-09T19:43:16.418751Z","iopub.status.idle":"2025-11-09T19:43:16.430234Z","shell.execute_reply.started":"2025-11-09T19:43:16.418695Z","shell.execute_reply":"2025-11-09T19:43:16.429332Z"},"papermill":{"duration":1.200669,"end_time":"2024-10-15T07:02:07.760756","exception":false,"start_time":"2024-10-15T07:02:06.560087","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openai -q","metadata":{"execution":{"iopub.status.busy":"2025-11-09T09:48:15.031133Z","iopub.execute_input":"2025-11-09T09:48:15.031687Z","iopub.status.idle":"2025-11-09T09:48:20.533851Z","shell.execute_reply.started":"2025-11-09T09:48:15.031653Z","shell.execute_reply":"2025-11-09T09:48:20.532279Z"},"papermill":{"duration":14.028138,"end_time":"2024-10-15T07:02:21.798426","exception":false,"start_time":"2024-10-15T07:02:07.770288","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nfrom openai import OpenAI\nimport pandas as pd\nimport json","metadata":{"execution":{"iopub.status.busy":"2025-11-09T09:48:20.535450Z","iopub.execute_input":"2025-11-09T09:48:20.535760Z","iopub.status.idle":"2025-11-09T09:48:22.130154Z","shell.execute_reply.started":"2025-11-09T09:48:20.535735Z","shell.execute_reply":"2025-11-09T09:48:22.129263Z"},"papermill":{"duration":2.661087,"end_time":"2024-10-15T07:02:24.469342","exception":false,"start_time":"2024-10-15T07:02:21.808255","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngpt_key = user_secrets.get_secret(\"GPT_key\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:48:22.132333Z","iopub.execute_input":"2025-11-09T09:48:22.132891Z","iopub.status.idle":"2025-11-09T09:48:22.229669Z","shell.execute_reply.started":"2025-11-09T09:48:22.132861Z","shell.execute_reply":"2025-11-09T09:48:22.228651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"client = OpenAI(api_key = gpt_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:48:22.231186Z","iopub.execute_input":"2025-11-09T09:48:22.231544Z","iopub.status.idle":"2025-11-09T09:48:22.432719Z","shell.execute_reply.started":"2025-11-09T09:48:22.231510Z","shell.execute_reply":"2025-11-09T09:48:22.431582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def summarize(system, data):\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": system},\n            {\"role\": \"user\", \"content\": data}\n        ],\n        response_format={\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"summarization_response\",\n                \"strict\": True,\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"samples\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"id\": {\n                                        \"type\": \"integer\"\n                                    },\n                                    \"summary\": {\n                                        \"type\": \"string\"\n                                    }\n                                },\n                                \"required\": [\n                                    \"id\", \"summary\"\n                                ],\n                                \"additionalProperties\": False\n                            }\n                        }\n                    },\n                    \"required\": [\n                        \"samples\"\n                    ],\n                    \"additionalProperties\": False\n                }\n            }\n        }\n    )\n\n    return response.choices[0].message.content","metadata":{"execution":{"iopub.status.busy":"2025-11-09T09:48:22.433897Z","iopub.execute_input":"2025-11-09T09:48:22.434276Z","iopub.status.idle":"2025-11-09T09:48:22.441232Z","shell.execute_reply.started":"2025-11-09T09:48:22.434240Z","shell.execute_reply":"2025-11-09T09:48:22.440100Z"},"papermill":{"duration":0.04683,"end_time":"2024-10-15T07:02:24.525990","exception":false,"start_time":"2024-10-15T07:02:24.479160","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_prompt = ' You will output in JSON, where the samples are gonna be in a list.'","metadata":{"execution":{"iopub.status.busy":"2025-11-09T09:48:22.442076Z","iopub.execute_input":"2025-11-09T09:48:22.442450Z","iopub.status.idle":"2025-11-09T09:48:22.462858Z","shell.execute_reply.started":"2025-11-09T09:48:22.442415Z","shell.execute_reply":"2025-11-09T09:48:22.461762Z"},"papermill":{"duration":0.018747,"end_time":"2024-10-15T07:02:24.554382","exception":false,"start_time":"2024-10-15T07:02:24.535635","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### bangla prompt","metadata":{}},{"cell_type":"code","source":"base_prompt = \"\"\"\nYou are an expert in natural language processing and text summarization. Your task is to summarize Bengali text into a concise and meaningful version while preserving the key points and overall meaning.\n\nFollow these steps:\n1. Read the input Bengali text carefully.\n2. Identify the main ideas, key points, and essential information.\n3. Write a summary that is shorter than the original text but retains the core meaning.\n\nYou will receive an array of objects, each containing an 'id' and 'text'.\n\"\"\"\n\nbangla_system_prompt = base_prompt + output_prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:48:22.463832Z","iopub.execute_input":"2025-11-09T09:48:22.464211Z","iopub.status.idle":"2025-11-09T09:48:22.482069Z","shell.execute_reply.started":"2025-11-09T09:48:22.464183Z","shell.execute_reply":"2025-11-09T09:48:22.480989Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### codemixed prompt","metadata":{}},{"cell_type":"code","source":"base_prompt = \"\"\"\nYou are an expert in natural language processing and text summarization. Your task is to summarize codemixed Bengali text into a concise and meaningful version while preserving the key points and overall meaning.\n\nFollow these steps:\n1. Read the input Bengali text carefully.\n2. Identify the main ideas, key points, and essential information.\n3. Write a summary that is shorter than the original text but retains the core meaning.\n\nYou will receive an array of objects, each containing an 'id' and 'text'.\n\"\"\"\n\ncodemixed_system_prompt = base_prompt + output_prompt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:48:23.883529Z","iopub.execute_input":"2025-11-09T09:48:23.883885Z","iopub.status.idle":"2025-11-09T09:48:23.888751Z","shell.execute_reply.started":"2025-11-09T09:48:23.883862Z","shell.execute_reply":"2025-11-09T09:48:23.887620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/codemixed-further-experiments-dataset/further_experiments/xl_sum_80.csv')\n# df = df[:5]\n# test_df\ndf.rename(columns = {'id':'dataset_id'}, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2025-11-09T09:48:24.940171Z","iopub.execute_input":"2025-11-09T09:48:24.940701Z","iopub.status.idle":"2025-11-09T09:48:25.577609Z","shell.execute_reply.started":"2025-11-09T09:48:24.940663Z","shell.execute_reply":"2025-11-09T09:48:25.576698Z"},"papermill":{"duration":0.096082,"end_time":"2024-10-15T07:02:24.948189","exception":false,"start_time":"2024-10-15T07:02:24.852107","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:56.959308Z","iopub.execute_input":"2025-11-09T09:52:56.959845Z","iopub.status.idle":"2025-11-09T09:52:56.980041Z","shell.execute_reply.started":"2025-11-09T09:52:56.959799Z","shell.execute_reply":"2025-11-09T09:52:56.978830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.reset_index(drop=True)\ndf['id'] = df.index + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:56.981509Z","iopub.execute_input":"2025-11-09T09:52:56.981880Z","iopub.status.idle":"2025-11-09T09:52:57.005484Z","shell.execute_reply.started":"2025-11-09T09:52:56.981852Z","shell.execute_reply":"2025-11-09T09:52:57.004420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir = 'output/gpt-4o'\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:50:40.865771Z","iopub.execute_input":"2025-11-09T09:50:40.866111Z","iopub.status.idle":"2025-11-09T09:50:40.871690Z","shell.execute_reply.started":"2025-11-09T09:50:40.866087Z","shell.execute_reply":"2025-11-09T09:50:40.870169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### helper functions","metadata":{}},{"cell_type":"code","source":"def process_text(text):\n    return text.replace('\\n', ' ')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:50:41.727401Z","iopub.execute_input":"2025-11-09T09:50:41.727800Z","iopub.status.idle":"2025-11-09T09:50:41.732672Z","shell.execute_reply.started":"2025-11-09T09:50:41.727768Z","shell.execute_reply":"2025-11-09T09:50:41.731323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk_size = 10\n\ndef process_chunks(column):\n    chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:50:43.832676Z","iopub.execute_input":"2025-11-09T09:50:43.833074Z","iopub.status.idle":"2025-11-09T09:50:43.838052Z","shell.execute_reply.started":"2025-11-09T09:50:43.833043Z","shell.execute_reply":"2025-11-09T09:50:43.836879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_chunk_list(chunks, column):\n    chunk_list = []\n    for i, chunk in enumerate(chunks):\n        start_id = chunk.index[0] + 1\n        end_id = chunk.index[-1] + 1\n        \n        user_prompt = \"\\n\".join([f\"{row['id']}: {process_text(row[column])}\" for _, row in chunk.iterrows()])\n        \n        chunk_dict = {\n            'chunk_name': f\"{start_id}-{end_id}\",\n            'user_prompt': user_prompt\n        }\n        \n        chunk_list.append(chunk_dict)\n    return chunk_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:50:43.900140Z","iopub.execute_input":"2025-11-09T09:50:43.900564Z","iopub.status.idle":"2025-11-09T09:50:43.906540Z","shell.execute_reply.started":"2025-11-09T09:50:43.900534Z","shell.execute_reply":"2025-11-09T09:50:43.905466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def llm_prediction(chunk_list):\n    final_df = pd.DataFrame()\n    for chunk in chunk_list:\n        try:\n            response = summarize(codemixed_system_prompt, chunk['user_prompt'])\n            response_object = json.loads(response)\n            output_df = pd.DataFrame(response_object['samples'])\n            final_df = pd.concat([final_df, output_df], ignore_index = True)\n            \n    #         output_df.to_csv(output_file, index=False)\n        except Exception as e:\n            print(f\"An error occurred: {e}\" + chunk['chunk_name'])\n    return final_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:50:52.213775Z","iopub.execute_input":"2025-11-09T09:50:52.214136Z","iopub.status.idle":"2025-11-09T09:50:52.219537Z","shell.execute_reply.started":"2025-11-09T09:50:52.214108Z","shell.execute_reply":"2025-11-09T09:50:52.218514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_prediction(final_df):\n    result_df = pd.merge(df, final_df, on = 'id', how = 'inner')\n    result_df.dropna(inplace=True)\n    return result_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:54:38.036631Z","iopub.execute_input":"2025-11-09T09:54:38.037025Z","iopub.status.idle":"2025-11-09T09:54:38.041928Z","shell.execute_reply.started":"2025-11-09T09:54:38.036996Z","shell.execute_reply":"2025-11-09T09:54:38.040835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### classification score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ndef classification(y_true, y_pred):\n    report = classification_report(y_true, y_pred, digits = 4)\n    print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:51:31.328755Z","iopub.execute_input":"2025-11-09T09:51:31.329171Z","iopub.status.idle":"2025-11-09T09:51:32.061724Z","shell.execute_reply.started":"2025-11-09T09:51:31.329141Z","shell.execute_reply":"2025-11-09T09:51:32.060580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### generation score","metadata":{}},{"cell_type":"code","source":"!pip install torch -q\n!pip install bert_score -q\n!pip install torchmetrics -q\n!pip install inltk -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:51:32.977614Z","iopub.execute_input":"2025-11-09T09:51:32.978186Z","iopub.status.idle":"2025-11-09T09:51:56.175835Z","shell.execute_reply.started":"2025-11-09T09:51:32.978153Z","shell.execute_reply":"2025-11-09T09:51:56.174285Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install rouge_score -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:51:56.177770Z","iopub.execute_input":"2025-11-09T09:51:56.178102Z","iopub.status.idle":"2025-11-09T09:52:02.896845Z","shell.execute_reply.started":"2025-11-09T09:51:56.178075Z","shell.execute_reply":"2025-11-09T09:52:02.895386Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade nltk -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:02.899073Z","iopub.execute_input":"2025-11-09T09:52:02.899422Z","iopub.status.idle":"2025-11-09T09:52:09.310303Z","shell.execute_reply.started":"2025-11-09T09:52:02.899391Z","shell.execute_reply":"2025-11-09T09:52:09.308901Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install evaluate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:09.312843Z","iopub.execute_input":"2025-11-09T09:52:09.313271Z","iopub.status.idle":"2025-11-09T09:52:14.127166Z","shell.execute_reply.started":"2025-11-09T09:52:09.313237Z","shell.execute_reply":"2025-11-09T09:52:14.125935Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/csebuetnlp/normalizer -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:14.128421Z","iopub.execute_input":"2025-11-09T09:52:14.128771Z","iopub.status.idle":"2025-11-09T09:52:26.557831Z","shell.execute_reply.started":"2025-11-09T09:52:14.128738Z","shell.execute_reply":"2025-11-09T09:52:26.556712Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom torchmetrics.text.bert import BERTScore\nimport torch\nimport bert_score\nfrom bert_score import score\nimport nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nfrom nltk.translate.meteor_score import meteor_score\nfrom nltk.tokenize import word_tokenize\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction, closest_ref_length, brevity_penalty\nimport math\nfrom tqdm import tqdm\n# from datasets import load_metric\n# rouge_metric = load_metric(\"rouge\")\nimport evaluate\nmetric = evaluate.load(\"rouge\")\nfrom normalizer import normalize\nfrom nltk.util import ngrams","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:26.559081Z","iopub.execute_input":"2025-11-09T09:52:26.559501Z","iopub.status.idle":"2025-11-09T09:52:56.593154Z","shell.execute_reply.started":"2025-11-09T09:52:26.559412Z","shell.execute_reply":"2025-11-09T09:52:56.592009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nnltk.download('punkt_tab')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:56.594290Z","iopub.execute_input":"2025-11-09T09:52:56.595156Z","iopub.status.idle":"2025-11-09T09:52:56.849460Z","shell.execute_reply.started":"2025-11-09T09:52:56.595113Z","shell.execute_reply":"2025-11-09T09:52:56.848244Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_bleu(reference_sentence, candidate_sentence):\n  reference = [word_tokenize(reference_sentence)]\n  candidate = word_tokenize(candidate_sentence)\n\n  smoothing_function = SmoothingFunction().method1\n\n  bl = sentence_bleu(reference, candidate, weights=(1, 0.5, 0.33, 0.25), smoothing_function=SmoothingFunction().method1)\n\n  hyp_len = len(candidate)\n  ref_len = len(reference[0])\n  closest_ref_len =  closest_ref_length(reference, hyp_len)\n  bp = brevity_penalty(closest_ref_len, hyp_len)\n\n  ratio = hyp_len/ref_len\n\n  return bl, bp, ratio\n\n# Example reference and candidate sentences in Bangla\nreference_sentence = \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"\ncandidate_sentence = \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"\ncalculate_bleu(reference_sentence, candidate_sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:56.852758Z","iopub.execute_input":"2025-11-09T09:52:56.853118Z","iopub.status.idle":"2025-11-09T09:52:56.890650Z","shell.execute_reply.started":"2025-11-09T09:52:56.853085Z","shell.execute_reply":"2025-11-09T09:52:56.889670Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_bleu_script(df, true_col, pred_col):\n    total_bleu = 0\n    total_bp = 0\n    total_ratio = 0\n    for reference_sentence, candidate_sentence in zip(df[true_col], df[pred_col]):\n      # print(reference_sentence)\n      # print(candidate_sentence)\n      bleu, bp, ratio = calculate_bleu(str(reference_sentence), str(candidate_sentence))\n      total_bleu += bleu\n      total_bp += bp\n      total_ratio += ratio\n    \n    bleu = total_bleu/df.shape[0]\n    bp = total_bp/df.shape[0]\n    ratio = total_ratio/df.shape[0]\n    print(f\"bleu: {bleu}, bp: {bp}, ratio: {ratio}\")\n    return {'bleu': bleu,'bp': bp, 'ratio': ratio}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:02:13.308998Z","iopub.execute_input":"2025-11-09T10:02:13.309424Z","iopub.status.idle":"2025-11-09T10:02:13.318165Z","shell.execute_reply.started":"2025-11-09T10:02:13.309384Z","shell.execute_reply":"2025-11-09T10:02:13.316230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to calculate ROUGE-1, ROUGE-2, and ROUGE-L scores for a pair of texts\ndef calculate_rouge_scores(reference_tokens, system_tokens):\n    def lcs(X, Y):\n        m, n = len(X), len(Y)\n        dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n        for i in range(1, m + 1):\n            for j in range(1, n + 1):\n                if X[i - 1] == Y[j - 1]:\n                    dp[i][j] = dp[i - 1][j - 1] + 1\n                else:\n                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n\n        return dp[m][n]\n\n    # Calculate ROUGE-1 (unigram) scores\n    reference_unigrams = set(reference_tokens)\n    system_unigrams = set(system_tokens)\n    overlap_rouge1 = len(reference_unigrams.intersection(system_unigrams))\n    precision_rouge1 = overlap_rouge1 / len(system_unigrams)\n    recall_rouge1 = overlap_rouge1 / len(reference_unigrams)\n    r1_t = 1 if precision_rouge1 + recall_rouge1 == 0 else 0\n    f1_rouge1 = 2 * (precision_rouge1 * recall_rouge1) / (precision_rouge1 + recall_rouge1 + r1_t)\n\n    # Calculate ROUGE-2 (bigram) scores\n    reference_bigrams = set(ngrams(reference_tokens, 2))\n    system_bigrams = set(ngrams(system_tokens, 2))\n\n\n    overlap_rouge2 = len(reference_bigrams.intersection(system_bigrams))\n    if len(system_bigrams) == 0:\n       precision_rouge2 = 0\n    else:\n      precision_rouge2 = overlap_rouge2 / len(system_bigrams)\n    if len(reference_bigrams) == 0:\n       recall_rouge2 = 0\n    else:\n      recall_rouge2 = overlap_rouge2 / len(reference_bigrams)\n    r2_t = 1 if precision_rouge2 + recall_rouge2 == 0 else 1\n    f1_rouge2 = 2 * (precision_rouge2 * recall_rouge2) / (precision_rouge2 + recall_rouge2 + r2_t)\n\n    # Calculate ROUGE-L scores\n    lcs_length = lcs(reference_tokens, system_tokens)\n    precision_rougeL = lcs_length / len(system_tokens)\n    recall_rougeL = lcs_length / len(reference_tokens)\n    rL_t = 1 if precision_rougeL + recall_rougeL == 0 else 0\n    f1_rougeL = 2 * (precision_rougeL * recall_rougeL) / (precision_rougeL + recall_rougeL + rL_t)\n\n    return {\n        'ROUGE-1 Precision': precision_rouge1,\n        'ROUGE-1 Recall': recall_rouge1,\n        'ROUGE-1 F1': f1_rouge1,\n        'ROUGE-2 Precision': precision_rouge2,\n        'ROUGE-2 Recall': recall_rouge2,\n        'ROUGE-2 F1': f1_rouge2,\n        'ROUGE-L Precision': precision_rougeL,\n        'ROUGE-L Recall': recall_rougeL,\n        'ROUGE-L F1': f1_rougeL,\n    }\n\n# Function to calculate the average of ROUGE scores for an array of text pairs\ndef calculate_average_rouge_scores(reference_texts, system_texts):\n    total_scores = {\n        'ROUGE-1 Precision': 0,\n        'ROUGE-1 Recall': 0,\n        'ROUGE-1 F1': 0,\n        'ROUGE-2 Precision': 0,\n        'ROUGE-2 Recall': 0,\n        'ROUGE-2 F1': 0,\n        'ROUGE-L Precision': 0,\n        'ROUGE-L Recall': 0,\n        'ROUGE-L F1': 0,\n    }\n\n    num_pairs = len(reference_texts)\n\n    for i in range(num_pairs):\n        reference_text = reference_texts[i]\n        system_text = system_texts[i]\n\n        reference_tokens = nltk.word_tokenize(reference_text)\n        system_tokens = nltk.word_tokenize(system_text)\n\n        scores = calculate_rouge_scores(reference_tokens, system_tokens)\n\n        for key, value in scores.items():\n            total_scores[key] += value\n\n    # Calculate the average scores\n    average_scores = {key: value / num_pairs for key, value in total_scores.items()}\n\n    return average_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:56.899656Z","iopub.execute_input":"2025-11-09T09:52:56.899992Z","iopub.status.idle":"2025-11-09T09:52:56.921572Z","shell.execute_reply.started":"2025-11-09T09:52:56.899966Z","shell.execute_reply":"2025-11-09T09:52:56.920260Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_rouge(df, true_col, pred_col):   \n    # Example usage with an array of reference and system texts\n    reference_texts = [normalize(str(sentence)) for sentence in df[true_col].tolist()]\n    system_texts = [normalize(str(sentence)) for sentence in df[pred_col].tolist()]\n    \n    average_scores = calculate_average_rouge_scores(reference_texts, system_texts)\n    print(\"Average ROUGE Scores:\")\n    print(\"-\"*30)\n    for key, value in average_scores.items():\n        print(key + \": {:.4f}\".format(value))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:52:56.922682Z","iopub.execute_input":"2025-11-09T09:52:56.922992Z","iopub.status.idle":"2025-11-09T09:52:56.937013Z","shell.execute_reply.started":"2025-11-09T09:52:56.922966Z","shell.execute_reply":"2025-11-09T09:52:56.935864Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_scores_generation_task(result_df):\n    true_col = 'summary_x'\n    pred_col = 'summary_y'\n    calculate_rouge(result_df, true_col, pred_col)\n    run_bleu_script(result_df, true_col, pred_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:59:19.813430Z","iopub.execute_input":"2025-11-09T09:59:19.813838Z","iopub.status.idle":"2025-11-09T09:59:19.818810Z","shell.execute_reply.started":"2025-11-09T09:59:19.813809Z","shell.execute_reply":"2025-11-09T09:59:19.817457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## choose colum","metadata":{"papermill":{"duration":0.009506,"end_time":"2024-10-15T07:02:25.074257","exception":false,"start_time":"2024-10-15T07:02:25.064751","status":"completed"},"tags":[]}},{"cell_type":"code","source":"columns = [ 'perturbed_text_words','perturbed_text_sentences', 'perturbed_text_salient']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T09:57:22.589913Z","iopub.execute_input":"2025-11-09T09:57:22.590392Z","iopub.status.idle":"2025-11-09T09:57:22.596132Z","shell.execute_reply.started":"2025-11-09T09:57:22.590330Z","shell.execute_reply":"2025-11-09T09:57:22.594941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for column in columns:\n    print(column)\n    chunks = process_chunks(column)\n    chunk_list = generate_chunk_list(chunks, column)\n    prediction_df = llm_prediction(chunk_list)\n    result_df = process_prediction(prediction_df)\n    calculate_scores_generation_task(result_df)\n\n    final_output_file = os.path.join(output_dir, f\"xl_sum_{column}.csv\")\n    result_df.to_csv(final_output_file, index=False)\n    print(f\"Final DataFrame saved to {final_output_file}\")\n    print()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:02:18.825640Z","iopub.execute_input":"2025-11-09T10:02:18.826054Z","iopub.status.idle":"2025-11-09T10:02:47.119308Z","shell.execute_reply.started":"2025-11-09T10:02:18.826024Z","shell.execute_reply":"2025-11-09T10:02:47.118199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}